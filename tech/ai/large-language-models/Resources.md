- https://github.com/sw-yx/ai-notes
- https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-chat/README.md
- https://github.com/mlc-ai/web-llm
  - Bringing large-language models and chat to web browsers. Everything runs inside the browser with no server support. 
  - #webgpu
- https://github.com/rustformers/llm
- models you can run on CPU
  - https://brezular.com/2023/04/21/running-large-language-models-on-cpu/
  - Alpaca.cpp
    - https://github.com/antimatter15/alpaca.cpp
  - llma.cpp
    - https://github.com/ggerganov/llama.cpp
  - GPT4All
  - GPT4All-J
  - https://github.com/jncraton/languagemodels
    - Explore large language models on any computer with 512MB of RAM 
    - https://www.reddit.com/r/LocalLLaMA/comments/14btk3a/explore_large_language_models_on_any_computer/
- You can run these models with HuggingFaceHub, and its Langchain adapter
- https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard
- https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models
- https://github.com/go-skynet/LocalAI
  - https://localai.io/

## BERT
- https://arxiv.org/abs/2304.00958 

## Anthropic Claude

## Alpaca
- https://crfm.stanford.edu/2023/03/13/alpaca.html
- https://github.com/tatsu-lab/stanford_alpaca
- https://github.com/antimatter15/alpaca.cpp

## LLaMa

- https://www.reddit.com/r/LocalLLaMA

## Vicuna

## GPT-J

## NanoGPT

## Lit-llama

https://github.com/Lightning-AI/lit-llama 

## GPT4ALL

- https://gpt4all.io/index.html 
  - https://github.com/nomic-ai/gpt4all

## StableML

## Falcon-40b

## llama.cpp

- https://github.com/oobabooga/text-generation-webui
- https://github.com/nat/openplayground

## PaLM (Pathways Language Model)
## Google PaLM (Pathways Language Model)

## Microsoft Semantic Kernel

## ControlNet

## LangChain

## Lhama index

## GPT-neo-X

## Tools

- https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/pages/tools.en.mdx
- https://poe.com/
  - try many language models in a single website
- https://github.com/Lightning-AI 
  - Lightning AI is the first operating system for AI. Build state-of-the art models and use them inside Lightning Apps (end-to-end ML systems).
- https://github.com/r2d4/rellm 
  - Get structured data out of LLMs
- https://github.com/imartinez/privateGPT
  - https://github.com/PromtEngineer/localGPT
- https://argilla.io/
- GPTCache
  - https://gptcache.readthedocs.io/
  - https://github.com/zilliztech/GPTCache
  - Semantic cache for LLMs. Fully integrated with LangChain and llama_index. 

## Prompt Engineering

- https://github.com/dair-ai/Prompt-Engineering-Guide
  - https://www.promptingguide.ai/
  - https://youtu.be/dOxUroR57xs
- Chain-of-though prompting

## Approaches

- https://medium.com/@imicknl/how-to-create-a-private-chatgpt-with-your-own-data-15754e6378a1
- https://github.com/Azure-Samples/azure-search-openai-demo/tree/main/app/backend/approaches 
- https://github.com/FranxYao/chain-of-thought-hub

## Datasets

- https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/pages/datasets.en.mdx

## People

- https://twitter.com/bentossell
- https://medium.com/@natashanewbold

## Projects
- https://github.com/0hq/WebGPT 
- https://github.com/OpenNMT/CTranslate2
  - Fast inference engine for Transformer models

## Introductions 

- https://www.economist.com/interactive/science-and-technology/2023/04/22/large-creative-ai-models-will-transform-how-we-live-and-work 